{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Copy of Copy of EP3_2_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jw-t6rG1kNdM",
        "e5PdpfHenjKD"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mTzQJGJnHP_"
      },
      "source": [
        "# MAC0417/5768 - Visão e Processamento de Imagens (2021)\n",
        "\n",
        "Exercício Programa 3.2 - Classificação de imagens\n",
        "\n",
        "Gabriela Melo e Richard Block\n",
        "\n",
        "Projeto GitHub: https://github.com/gabi-melo/image_processing/tree/main/EP3\n",
        "\n",
        "Base de imagens: https://www.kaggle.com/gabrielamelo/image-processing\n"
      ],
      "id": "7mTzQJGJnHP_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5PdpfHenjKD"
      },
      "source": [
        "# Resumo"
      ],
      "id": "e5PdpfHenjKD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d831991"
      },
      "source": [
        "Nessa parte do EP realizamos a etapa de classificação, baseada nas imagens binárias com Feret Box obtidas na primeira parte. As imagens foram redimensionaras para que todas as classes apresentem o mesmo tamanho. Os dados foram separados em conjuntos de treino e de teste. Então foi executada uma etapa de preparação para o aprendizado, com a extração do vetor de características. Para isso, foi utilizada a análise de componentes principais (PCA). A PCA descobre os eixos/vetores de maior variância dos dados, fazendo uma análise a partir da matriz de covariância. O vetor que indica a maior variabilidade dos dados é o primeiro autovetor. O vetor perpendicular é o segundo autovetor, indicando o segundo vetor de maior variabilidade. A transformada PCA muda a coordenada dos pontos definida pelos autovetores, realizando a redução da dimensionalidade.\n",
        "\n",
        "O vetor de características resultante foi então submetido à classificação, utilizando um algoritmo de máquina de suporte vetorial (SVM). Um classificador define um modelo algébrico para qual é a superfície de decisão. O modelo mais simples é uma linha reta que divide o conjunto de dados para fazer a separação dos dados entre as diferentes classes. As máquinas de suporte vetorial procuram criar uma reta que define uma função critério, a qual é otimizada. O procedimento de otimização faz calcula qual é a linha reta que maximiza as distâncias dos pontos mais próximos da reta. O processo de treinamento de SVM descobre qual é essa linha reta que apresenta a maior distância possível de todas as classes. Esse treino foi realizado exclusivamente nos dados do conjunto de treino.\n",
        "Foram calculadas métricas de avaliação da qualidade do modelo nos dados do conjunto de teste. Foi realizada a predição dos rótulos das classes do conjunto de teste, e foram computadas variáveis da performance do classificador."
      ],
      "id": "0d831991"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptD4XbFejJMW"
      },
      "source": [
        "# Download do Kaggle dataset"
      ],
      "id": "ptD4XbFejJMW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyUtaynvT9M",
        "outputId": "05559fe2-5b70-4470-d39a-b718e3fd4dac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "id": "9cyUtaynvT9M",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2Cq8blv7dD",
        "outputId": "e41a2f81-be5e-464c-da04-9e8df089fc90"
      },
      "source": [
        "# download do dataset\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!kaggle datasets download -d gabrielamelo/image-processing/objects"
      ],
      "id": "PN2Cq8blv7dD",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaW0DCAtwWmp"
      },
      "source": [
        "# conferir conteúdo do dataset\n",
        "!ls \"/content/gdrive/My Drive/Kaggle/objects\""
      ],
      "id": "XaW0DCAtwWmp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6f7270"
      },
      "source": [
        "# Classificação usando SVM"
      ],
      "id": "7d6f7270"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk2toRziweUs"
      },
      "source": [
        "As imagens já foram pré-processadas, todas padronizadas no tamanho (64, 64)"
      ],
      "id": "Pk2toRziweUs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_us6Bj7xDNZ"
      },
      "source": [
        "# importar bibliotecas\n",
        "from glob import glob \n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from time import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC"
      ],
      "id": "S_us6Bj7xDNZ",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bse4_1SUFrVl",
        "outputId": "5fc4d71a-cefd-4866-e37b-260985c844f8"
      },
      "source": [
        "## definir variáveis dos dados\n",
        "\n",
        "paths = glob('/content/gdrive/My Drive/Kaggle/objects/*.jpg') # path para os objects\n",
        "\n",
        "# criar variável para os arrays das imagens\n",
        "X = []\n",
        "\n",
        "for path in paths:\n",
        "\n",
        "  an_image = Image.open(path)\n",
        "  image_sequence = an_image.getdata()\n",
        "  image_array = np.array(image_sequence)\n",
        "  X.append(image_array)\n",
        "\n",
        "X = np.array(X)\n",
        "print(X)\n",
        "\n",
        "# criar variável para os rótulos das imagens\n",
        "y = []\n",
        "\n",
        "for path in paths:\n",
        "    \n",
        "  img_class = path.split('/')[-1].split('_')[0]\n",
        "  y.append(img_class)\n",
        "\n",
        "y = np.array(y)\n",
        "print(y)"
      ],
      "id": "bse4_1SUFrVl",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[101  96  89 ... 188 193 171]\n",
            " [109  91 148 ... 135 165 170]\n",
            " [  9   9   9 ... 106 107 107]\n",
            " ...\n",
            " [127 111 130 ... 205 203 210]\n",
            " [110 109 111 ... 138 139 139]\n",
            " [ 44  45  45 ...  26  25  25]]\n",
            "['livro' 'copo' 'oculos' ... 'chinelo' 'livro' 'escova']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sRtF-ATxrVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97a05f5-7379-47c0-c882-4f1e7200cb2a"
      },
      "source": [
        "## dividir a amostra em conjuntos de treinamento e teste\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "id": "4sRtF-ATxrVF",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3019, 4096) (1007, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPeEZ7A8x4_G"
      },
      "source": [
        "## Análise de componentes principais (PCA)"
      ],
      "id": "QPeEZ7A8x4_G"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAYS_i-yMMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1170b0-d8f6-477c-b783-9face0312bc8"
      },
      "source": [
        "# calcular os autovetores/extrair os vetores de características\n",
        "\n",
        "pca = PCA(n_components=150, whiten=True)\n",
        "pca.fit(X_train)"
      ],
      "id": "flAYS_i-yMMU",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYFohPhhzMBA"
      },
      "source": [
        "Os dados de treinamento e de teste projetados nas bases do PCA."
      ],
      "id": "FYFohPhhzMBA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhgAiLdCzfR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655c14f1-46ec-4366-d1e6-8df0b0e907c4"
      },
      "source": [
        "# calcular as dimensões da transformada de PCA\n",
        "\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "print(X_train_pca.shape)"
      ],
      "id": "AhgAiLdCzfR3",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3019, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1FuLaldzjAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146b29cd-1dbb-41d4-aff5-ef66d06762d3"
      },
      "source": [
        "print(X_test_pca.shape)"
      ],
      "id": "_1FuLaldzjAH",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1007, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a86nkr1BzkFf"
      },
      "source": [
        "## Classificação"
      ],
      "id": "a86nkr1BzkFf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzm7mCzJztAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4cf3a1-2d0e-41fd-937f-a2a11edbff11"
      },
      "source": [
        "# Treinamento do modelo de classificação SVM\n",
        "\n",
        "print(\"Fitting the classifier to the training set\")\n",
        "t0 = time()\n",
        "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
        "clf = GridSearchCV(\n",
        "    SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_train_pca, y_train) # ajuste da função critério\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\"Best estimator found by grid search:\")\n",
        "print(clf.best_estimator_)"
      ],
      "id": "Jzm7mCzJztAV",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the classifier to the training set\n",
            "done in 433.592s\n",
            "Best estimator found by grid search:\n",
            "SVC(C=1000.0, break_ties=False, cache_size=200, class_weight='balanced',\n",
            "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.0001,\n",
            "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
            "    shrinking=True, tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuXKiMzZz8st"
      },
      "source": [
        "## Métricas de classificação"
      ],
      "id": "wuXKiMzZz8st"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX1bR5zp0XxR"
      },
      "source": [
        "### Precisão, Recall, F1-Score e Suporte"
      ],
      "id": "rX1bR5zp0XxR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAcIOX5p0MiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15217dc5-b5f4-4ff0-e306-794977445a6b"
      },
      "source": [
        "# predição dos rótulos do test set\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "\n",
        "# variáveis da performance do classificador\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "id": "nAcIOX5p0MiV",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      caneta       0.01      0.29      0.03         7\n",
            "     chinelo       0.69      0.80      0.74        50\n",
            "        copo       0.58      0.62      0.60       137\n",
            "      escova       0.57      0.47      0.51       150\n",
            "       leite       0.84      0.68      0.75       124\n",
            "       livro       0.80      0.75      0.77       125\n",
            "      oculos       0.67      0.46      0.55       126\n",
            "     palheta       0.77      0.64      0.70       124\n",
            "     tesoura       0.79      0.61      0.69       164\n",
            "\n",
            "    accuracy                           0.61      1007\n",
            "   macro avg       0.64      0.59      0.59      1007\n",
            "weighted avg       0.71      0.61      0.65      1007\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmApuVcV0dH6"
      },
      "source": [
        "### Matriz de confusão\n",
        "Um classificador perfeito apresenta números diferentes de zero somente na diagonal principal, e zero no restante."
      ],
      "id": "xmApuVcV0dH6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvLXlDR0yBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab2616f-b66f-4bfa-e96a-f30a3ba1fe3f"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "id": "zqvLXlDR0yBq",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  2   1   0   1   0   2   0   1   0]\n",
            " [  5  40   1   2   0   0   1   0   1]\n",
            " [ 16   2  85  14   1   6   7   3   3]\n",
            " [ 33   1  17  70   9   4   2   6   8]\n",
            " [ 14   0   4  12  84   8   0   1   1]\n",
            " [ 14   1   5   5   4  94   2   0   0]\n",
            " [ 29   5  19   6   1   1  58   3   4]\n",
            " [  7   3   8   6   1   2   8  79  10]\n",
            " [ 26   5   8   7   0   1   8   9 100]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}