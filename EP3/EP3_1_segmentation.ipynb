{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "EP3_1_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Lb31rbgcn28T"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-t6rG1kNdM"
      },
      "source": [
        "# GABARITO"
      ],
      "id": "Jw-t6rG1kNdM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJIK_nD7kUPX"
      },
      "source": [
        "-----------PARTE I (3/3)----------------\n",
        "\n",
        "    Segmentação binária manual de 15% \n",
        "    Segmentação binária automática de todas as imagens. \n",
        "    Feret Box/ Blob das imagens segmentadas manualmente. \n",
        "    Feret Box/ Blob das imagens segmentadas automaticamente. \n",
        "\n",
        "-----------PARTE II (3/3)--------------\n",
        "\n",
        "    Extração das features. \n",
        "    PCA das features.\n",
        "    Classificação.\n",
        "\n",
        "-----------PARTE III (2/2)-------------\n",
        "\n",
        "    Cálculo das métricas de segmentação. \n",
        "    Cálculo das métricas de classificação.\n",
        "    Relatório. \n",
        "\n",
        "-----------PARTE IV (2/2)--------------\n",
        "\n",
        "    Breve introdução\n",
        "    Separar em tóp.\n",
        "    Git hub (atualizar o git com o ep3)\n",
        "    Cabeçalho dos int\n",
        "    Comentar cód.\n",
        "    Organização do código e notebook \n",
        "    Read-me (pode ser o read-me do git atualizado)\n",
        "\n",
        "NOTA (10/10)"
      ],
      "id": "qJIK_nD7kUPX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mTzQJGJnHP_"
      },
      "source": [
        "# MAC0417/5768 - Visão e Processamento de Imagens (2021)\n",
        "\n",
        "Exercício Programa 3.1 - Segmentação de imagens\n",
        "\n",
        "Gabriela Melo e Richard Block\n",
        "\n",
        "Projeto GitHub: https://github.com/gabi-melo/image_processing/tree/main/EP3\n",
        "\n",
        "Base de imagens: https://www.kaggle.com/gabrielamelo/image-processing\n"
      ],
      "id": "7mTzQJGJnHP_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5PdpfHenjKD"
      },
      "source": [
        "# Resumo\n",
        "\n",
        "Na primeira parte do EP realizamos a segmentação das imagens em níveis de cinza do dataset gerado no EP2. Duas formas de segmentação foram aplicadas: manual e automática. \n",
        "\n",
        "Para a segmentação manual, utilizamos cerca de 15% das imagens em níveis de cinza de cada classe de objetos. Foi empregado o programa Label Studio para a segmentação semântica com máscaras. A segmentação manual gerou imagens binárias, em que o valor de 0 corresponde ao fundo e o valor de 1 corresponde ao objeto, compondo o \"ground truth\" do dataset. Essas imagens binárias foram processadas utilizando um Feret Box para delimitar a área de interesse, fazendo com que a região a ser analisada na etapa de classificação (EP3.2) esteja restrita ao objeto, auxiliando a localização do objeto pelo algoritmo classificador.\n",
        "\n",
        "Para a segmentação automática usamos um método chamado U square Net, baseado numa arquitetura de rede profunda (disponível em https://arxiv.org/pdf/2005.09007.pdf). Métricas para a avaliação do modelo de segmentação foram computadas.\n",
        "\n"
      ],
      "id": "e5PdpfHenjKD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dza7XvA-w20E"
      },
      "source": [
        "# Download do Kaggle dataset"
      ],
      "id": "dza7XvA-w20E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyUtaynvT9M",
        "outputId": "5f5eb612-7170-49a9-ebe6-95dc5544ab2c"
      },
      "source": [
        "zfrom glob import glob \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "9cyUtaynvT9M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icol7d7hv1-P"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "id": "Icol7d7hv1-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2Cq8blv7dD",
        "outputId": "9d686729-d1ca-43fd-c438-31c4e6a417b3"
      },
      "source": [
        "# changing the working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "id": "PN2Cq8blv7dD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV1VeC5ZwLTY",
        "outputId": "68ffb693-93f2-4e39-f8f1-3be435df5f27"
      },
      "source": [
        "!kaggle datasets download -d gabrielamelo/image-processing"
      ],
      "id": "hV1VeC5ZwLTY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading image-processing.zip to /content/gdrive/My Drive/Kaggle\n",
            "100% 1.93G/1.93G [00:20<00:00, 39.9MB/s]\n",
            "100% 1.93G/1.93G [00:20<00:00, 101MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaW0DCAtwWmp",
        "outputId": "0e2bae23-1431-442f-80b7-75f82622fd92"
      },
      "source": [
        "# check content\n",
        "!ls"
      ],
      "id": "XaW0DCAtwWmp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmentedDataset  ground_truth\tnormalizedDataset\n",
            "dataset\t\t  kaggle.json\toriginalGrayDataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpC6q0Vfwe_Z"
      },
      "source": [
        "# unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "id": "KpC6q0Vfwe_Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOKEWw_iXQ5Z",
        "outputId": "c51da9dc-0fb0-42c8-d358-e848cd41c154"
      },
      "source": [
        "ls '/content/gdrive/My Drive/Kaggle/'"
      ],
      "id": "VOKEWw_iXQ5Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34maugmentedDataset\u001b[0m/  \u001b[01;34mground_truth\u001b[0m/  \u001b[01;34mnormalizedDataset\u001b[0m/\n",
            "\u001b[01;34mdataset\u001b[0m/           kaggle.json    \u001b[01;34moriginalGrayDataset\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-cAEl2pzPrz"
      },
      "source": [
        "for path in glob('./originalGrayDataset/originalGrayDataset/*.jpg'):\n",
        "    print(path)\n",
        "\n",
        "# print(glob('/content/gdrive/My Drive/Kaggle/originalGrayDataset/originalGrayDataset/*.jpg'))"
      ],
      "id": "5-cAEl2pzPrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZr-GNnio_ct"
      },
      "source": [
        "# Segmentação manual"
      ],
      "id": "rZr-GNnio_ct"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgShM9KxkguN"
      },
      "source": [
        "for path in glob('./ground_truth/ground_truth/*.npy'):\n",
        "    print(path)"
      ],
      "id": "vgShM9KxkguN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYuMsfDo7Ha"
      },
      "source": [
        "# Segmentação automática"
      ],
      "id": "vdYuMsfDo7Ha"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvAVgKs-nJDo"
      },
      "source": [
        "Separamos a tarefa de segmentação automática em duas partes:\n",
        "1. Criação das máscaras dos objetos, a segmentação de fato.\n",
        "2. O Feret Box / Blob da região dos objetos, e a padronização destes para a tarefa de classificação."
      ],
      "id": "rvAVgKs-nJDo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb31rbgcn28T"
      },
      "source": [
        "## 1.\n",
        "\n",
        "Fizemos uso de uma rede neural treinada, e usamos nossas imagens como testes da rede."
      ],
      "id": "Lb31rbgcn28T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GV4yFUQnGTy"
      },
      "source": [
        "# download do modelo pré-treinado\n",
        "!wget -O u2netp.pth https://drive.google.com/u/0/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy&export=download \n",
        "!wget -O u2netp.onnx https://drive.google.com/uc?id=1OPfir1PXZAABPEZpIppauGKDu8LYXoIm&authuser=0&export=download"
      ],
      "id": "0GV4yFUQnGTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNg4wBRdoNhA"
      },
      "source": [
        "#u2netp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "#import torch.nn.functional as F"
      ],
      "id": "GNg4wBRdoNhA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHCh4hiQpBIW"
      },
      "source": [
        "### Configurações da rede"
      ],
      "id": "pHCh4hiQpBIW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0RguzVJoRT6"
      },
      "source": [
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
        "        super(REBNCONV,self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return xout\n",
        "\n",
        "### RSU-7 ###\n",
        "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "#        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "# edit for onnx compatibility\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
        "        hx6up = self.upscore2(hx6d)\n",
        "        # print(hx6up.shape,hx5.shape)\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-6 ###\n",
        "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-5 ###\n",
        "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4 ###\n",
        "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4F ###\n",
        "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "##### U^2-Net ####\n",
        "class U2NET(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NET,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,32,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,32,128)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128,64,256)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256,128,512)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512,256,512)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512,256,512)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(1024,256,512)\n",
        "        self.stage4d = RSU4(1024,128,256)\n",
        "        self.stage3d = RSU5(512,64,128)\n",
        "        self.stage2d = RSU6(256,32,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(128,1,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(256,1,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(512,1,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(512,1,3,padding=1)\n",
        "\n",
        "        self.upscore6 = nn.Upsample(scale_factor=32,mode='bilinear',align_corners=True)\n",
        "        self.upscore5 = nn.Upsample(scale_factor=16,mode='bilinear',align_corners=True)\n",
        "        self.upscore4 = nn.Upsample(scale_factor=8,mode='bilinear',align_corners=True)\n",
        "        self.upscore3 = nn.Upsample(scale_factor=4,mode='bilinear',align_corners=True)\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear',align_corners=True)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = self.upscore2(hx6)\n",
        "\n",
        "        #-------------------- decoder --------------------\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = self.upscore2(d2)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = self.upscore3(d3)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = self.upscore4(d4)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = self.upscore5(d5)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = self.upscore6(d6)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "\n",
        "        F.sigmokd\n",
        "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)\n",
        "\n",
        "### U^2-Net small ###\n",
        "class U2NETP(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NETP,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,16,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,16,64)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(64,16,64)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(64,16,64)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(64,16,64)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(64,16,64)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(128,16,64)\n",
        "        self.stage4d = RSU4(128,16,64)\n",
        "        self.stage3d = RSU5(128,16,64)\n",
        "        self.stage2d = RSU6(128,16,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(64,1,3,padding=1)\n",
        "\n",
        "        self.upscore6 = nn.Upsample(scale_factor=32,mode='bilinear',align_corners=True)\n",
        "        self.upscore5 = nn.Upsample(scale_factor=16,mode='bilinear',align_corners=True)\n",
        "        self.upscore4 = nn.Upsample(scale_factor=8,mode='bilinear',align_corners=True)\n",
        "        self.upscore3 = nn.Upsample(scale_factor=4,mode='bilinear',align_corners=True)\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear',align_corners=True)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = self.upscore2(hx6)\n",
        "\n",
        "        #decoder\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = self.upscore2(d2)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = self.upscore3(d3)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = self.upscore4(d4)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = self.upscore5(d5)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = self.upscore6(d6)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "        # d00 = d0 + self.refconv(d0)\n",
        "\n",
        "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)"
      ],
      "id": "w0RguzVJoRT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1coQ-SYpLuW"
      },
      "source": [
        "net = U2NETP(3,1)"
      ],
      "id": "J1coQ-SYpLuW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIP48-PzpWFK"
      },
      "source": [
        "### Data loader e transformaçções das imagens para serem usadas na rede neural"
      ],
      "id": "OIP48-PzpWFK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R_8xgxXpOR7"
      },
      "source": [
        "# data loader\n",
        "from __future__ import print_function, division\n",
        "import glob\n",
        "import torch\n",
        "from skimage import io, transform, color\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "#==========================dataset load==========================\n",
        "class RescaleT(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\t# img = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\t# lbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\timg = transform.resize(image,(self.output_size,self.output_size),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(self.output_size,self.output_size),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\timg = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class RandomCrop(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size, (int, tuple))\n",
        "\t\tif isinstance(output_size, int):\n",
        "\t\t\tself.output_size = (output_size, output_size)\n",
        "\t\telse:\n",
        "\t\t\tassert len(output_size) == 2\n",
        "\t\t\tself.output_size = output_size\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\ttop = np.random.randint(0, h - new_h)\n",
        "\t\tleft = np.random.randint(0, w - new_w)\n",
        "\n",
        "\t\timage = image[top: top + new_h, left: left + new_w]\n",
        "\t\tlabel = label[top: top + new_h, left: left + new_w]\n",
        "\n",
        "\t\treturn {'imidx':imidx,'image':image, 'label':label}\n",
        "\n",
        "class ToTensor(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\timage = image/np.max(image)\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\tif image.shape[2]==1:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\telse:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class ToTensorLab(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\tdef __init__(self,flag=0):\n",
        "\t\tself.flag = flag\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label =sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\t# change the color space\n",
        "\t\tif self.flag == 2: # with rgb and Lab colors\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],6))\n",
        "\t\t\ttmpImgt = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImgt[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImgt = image\n",
        "\t\t\ttmpImgtl = color.rgb2lab(tmpImgt)\n",
        "\n",
        "\t\t\t# nomalize image to range [0,1]\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImgt[:,:,0]-np.min(tmpImgt[:,:,0]))/(np.max(tmpImgt[:,:,0])-np.min(tmpImgt[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImgt[:,:,1]-np.min(tmpImgt[:,:,1]))/(np.max(tmpImgt[:,:,1])-np.min(tmpImgt[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImgt[:,:,2]-np.min(tmpImgt[:,:,2]))/(np.max(tmpImgt[:,:,2])-np.min(tmpImgt[:,:,2]))\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImgtl[:,:,0]-np.min(tmpImgtl[:,:,0]))/(np.max(tmpImgtl[:,:,0])-np.min(tmpImgtl[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImgtl[:,:,1]-np.min(tmpImgtl[:,:,1]))/(np.max(tmpImgtl[:,:,1])-np.min(tmpImgtl[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImgtl[:,:,2]-np.min(tmpImgtl[:,:,2]))/(np.max(tmpImgtl[:,:,2])-np.min(tmpImgtl[:,:,2]))\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImg[:,:,3]-np.mean(tmpImg[:,:,3]))/np.std(tmpImg[:,:,3])\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImg[:,:,4]-np.mean(tmpImg[:,:,4]))/np.std(tmpImg[:,:,4])\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImg[:,:,5]-np.mean(tmpImg[:,:,5]))/np.std(tmpImg[:,:,5])\n",
        "\n",
        "\t\telif self.flag == 1: #with Lab color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg = image\n",
        "\n",
        "\t\t\ttmpImg = color.rgb2lab(tmpImg)\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.min(tmpImg[:,:,0]))/(np.max(tmpImg[:,:,0])-np.min(tmpImg[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.min(tmpImg[:,:,1]))/(np.max(tmpImg[:,:,1])-np.min(tmpImg[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.min(tmpImg[:,:,2]))/(np.max(tmpImg[:,:,2])-np.min(tmpImg[:,:,2]))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\n",
        "\t\telse: # with rgb color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\timage = image/np.max(image)\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class SalObjDataset(Dataset):\n",
        "\tdef __init__(self,img_name_list,lbl_name_list,transform=None):\n",
        "\t\t# self.root_dir = root_dir\n",
        "\t\t# self.image_name_list = glob.glob(image_dir+'*.png')\n",
        "\t\t# self.label_name_list = glob.glob(label_dir+'*.png')\n",
        "\t\tself.image_name_list = img_name_list\n",
        "\t\tself.label_name_list = lbl_name_list\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.image_name_list)\n",
        "\n",
        "\tdef __getitem__(self,idx):\n",
        "\n",
        "\t\t# image = Image.open(self.image_name_list[idx])#io.imread(self.image_name_list[idx])\n",
        "\t\t# label = Image.open(self.label_name_list[idx])#io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\timage = io.imread(self.image_name_list[idx])\n",
        "\t\timname = self.image_name_list[idx]\n",
        "\t\timidx = np.array([idx])\n",
        "\n",
        "\t\tif(0==len(self.label_name_list)):\n",
        "\t\t\tlabel_3 = np.zeros(image.shape)\n",
        "\t\telse:\n",
        "\t\t\tlabel_3 = io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\tlabel = np.zeros(label_3.shape[0:2])\n",
        "\t\tif(3==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3[:,:,0]\n",
        "\t\telif(2==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3\n",
        "\n",
        "\t\tif(3==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\t\telif(2==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\timage = image[:,:,np.newaxis]\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\n",
        "\t\tsample = {'imidx':imidx, 'image':image, 'label':label}\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\tsample = self.transform(sample)\n",
        "\n",
        "\t\treturn sample"
      ],
      "id": "8R_8xgxXpOR7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTibvwMopnAj"
      },
      "source": [
        "### Obtenção dos nossos dados para serem usados como teste da rede"
      ],
      "id": "YTibvwMopnAj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yD6378epiRx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "2yD6378epiRx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvMwUw4p4Z8"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/kaggle'"
      ],
      "id": "uJvMwUw4p4Z8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGsqtfBp7Lo"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/kaggle"
      ],
      "id": "DNGsqtfBp7Lo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ojU-R3_p9s3"
      },
      "source": [
        "!kaggle datasets download -d richardbarana/ep3-usp"
      ],
      "id": "8ojU-R3_p9s3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnuI-BMtqBJk"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "id": "WnuI-BMtqBJk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gf6EIO5qLxG"
      },
      "source": [
        "### Inicialização do modelo"
      ],
      "id": "4Gf6EIO5qLxG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1G3DyzzqEL9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms#, utils\n",
        "\n",
        "model_dir = './u2netp.pth'\n",
        "net.load_state_dict(torch.load(model_dir))\n",
        "if torch.cuda.is_available():\n",
        "  print(\"cuda is available\")\n",
        "  net.cuda()\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "id": "F1G3DyzzqEL9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVikVmgaqS7Q"
      },
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "\n",
        "# Create the right input shape (e.g. for an image)\n",
        "dummy_input = torch.randn(1, 3, 320, 320).cuda()\n",
        "\n",
        "torch.onnx.export(net, dummy_input, \"onnx_u2netp.onnx\", opset_version=11)\n",
        "# UserWarning: You are trying to export the model with onnx:Upsample for ONNX opset version 9.\n",
        "# This operator might cause results to not match the expected results by PyTorch.\n",
        "# ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11.\n",
        "# Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior \n",
        "# (like coordinate_transformation_mode and nearest_mode).\n",
        "# We recommend using opset 11 and above for models using this operator. \n",
        "#   \"\" + str(_export_onnx_opset_version) + \". \"\n",
        "# /usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_helper.py:182: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
        "#   warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")"
      ],
      "id": "kVikVmgaqS7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLd6tlrgqYeq"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/kaggle/augmentedDataset/"
      ],
      "id": "PLd6tlrgqYeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXGQ03DNqfHR"
      },
      "source": [
        "### Teste do modelo com as nossas imagens, e máscaras das imagens salvas"
      ],
      "id": "wXGQ03DNqfHR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0J-6mW5qb7v"
      },
      "source": [
        "img_name_list = glob.glob('./*.jpg')\n",
        "img_name_list"
      ],
      "id": "x0J-6mW5qb7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnpARr5yqmyF"
      },
      "source": [
        "net.eval()"
      ],
      "id": "lnpARr5yqmyF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTvYfxQcqqrX"
      },
      "source": [
        "test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
        "                                    lbl_name_list = [],\n",
        "                                    transform=transforms.Compose([RescaleT(320),\n",
        "                                                                  ToTensorLab(flag=0)])\n",
        "                                    )\n",
        "test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=1)"
      ],
      "id": "uTvYfxQcqqrX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6183OPHq2Ev"
      },
      "source": [
        "path_masks = r'/content/drive/My Drive/kaggle/masks/'\n",
        "\n",
        "def normPRED(d):\n",
        "    ma = torch.max(d)\n",
        "    mi = torch.min(d)\n",
        "\n",
        "    dn = (d-mi)/(ma-mi)\n",
        "\n",
        "    return dn\n",
        "\n",
        "\n",
        "def genImage(image_name,pred):\n",
        "\n",
        "    predict = pred\n",
        "    predict = predict.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
        "    img_name = image_name.split(\"/\")[-1]\n",
        "    image = io.imread(image_name)\n",
        "    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
        "\n",
        "    pb_np = np.array(imo)\n",
        "\n",
        "    aaa = img_name.split(\".\")\n",
        "    bbb = aaa[0:-1]\n",
        "    imidx = bbb[0]\n",
        "    for i in range(1,len(bbb)):\n",
        "        imidx = imidx + \".\" + bbb[i]\n",
        "\n",
        "    file_path = os.path.join(path_masks, img_name)\n",
        "    imo.save(file_path)\n",
        "\n",
        "    return imo\n",
        "\n",
        "# test_salobj_dataloader 에서 i_test랑 data_test를 어떻게 뽑아내지?\n",
        "for i_test, data_test in enumerate(test_salobj_dataloader):\n",
        "    print(\"inferencing:\",img_name_list[i_test].split(\"/\")[-1])\n",
        "    inputs_test = data_test['image']\n",
        "    inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "    inputs_test = Variable(inputs_test.cuda())\n",
        "    # inputs_test = Variable(inputs_test)\n",
        "    d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
        "\n",
        "    pred = d1[:,0,:,:]\n",
        "    pred = normPRED(pred)\n",
        "\n",
        "    genImage(img_name_list[i_test],pred)"
      ],
      "id": "-6183OPHq2Ev",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eTUW6IThK3K"
      },
      "source": [
        "## 2."
      ],
      "id": "3eTUW6IThK3K"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnezyGVheem"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from skimage import io"
      ],
      "id": "JsnezyGVheem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O6SmHoEhhRJ"
      },
      "source": [
        "%cd /content/drive/My Drive/kaggle"
      ],
      "id": "7O6SmHoEhhRJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5o6LnjhkrO"
      },
      "source": [
        "masks = []\n",
        "for root, dirs, files in os.walk('./masks'):\n",
        "    masks += glob.glob(os.path.join(root, '*.jpg'))"
      ],
      "id": "VL5o6LnjhkrO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMPohW_6hm0M"
      },
      "source": [
        "aug = []\n",
        "for root, dirs, files in os.walk('./augmentedDataset'):\n",
        "    aug += glob.glob(os.path.join(root, '*.jpg'))"
      ],
      "id": "SMPohW_6hm0M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMdWuecAhpLH"
      },
      "source": [
        "for idx, val in enumerate(masks):\n",
        "  im_mask = cv2.imread(val, 0)\n",
        "  im_name = val.split(\"/\")[-1]\n",
        "\n",
        "# Achar os contornos das máscaras\n",
        "  ret, thresh = cv2.threshold(im_mask, 127, 255, 0)\n",
        "  contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnt = contours[0]\n",
        "\n",
        "# Pegar as coordenadas dos retângulos e desenha-lo\n",
        "  x, y, w, h = cv2.boundingRect(cnt)\n",
        "  cv2.rectangle(im_mask, (x,y), (x+w, y+h), (0,255,0), 2)\n",
        "\n",
        "# Recortar os objetos das imagens e rescalar as imagens para classificação\n",
        "  im_aug = cv2.imread(aug[idx], 0)\n",
        "  cropped = im_aug[y-2:y+h+2, x-2:x+w+2]\n",
        "  res = cv2.resize(cropped, dsize=(64,64))\n",
        "  im_res = Image.fromarray(res)\n",
        "\n",
        "# Salvar as imagens\n",
        "  file_path = os.path.join('./objects', im_name)\n",
        "  im_res.save(file_path)"
      ],
      "id": "wMdWuecAhpLH",
      "execution_count": null,
      "outputs": []
    }
  ]
}