{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Copy of Copy of EP3_2_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jw-t6rG1kNdM",
        "e5PdpfHenjKD"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-t6rG1kNdM"
      },
      "source": [
        "# GABARITO"
      ],
      "id": "Jw-t6rG1kNdM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJhezyASnB0F"
      },
      "source": [
        "-----------PARTE II (3/3)--------------\n",
        "\n",
        "    Extração das features. \n",
        "    PCA das features.\n",
        "    Classificação.\n",
        "\n",
        "-----------PARTE III (2/2)-------------\n",
        "\n",
        "    Cálculo das métricas de classificação.\n",
        "    Relatório. \n",
        "\n",
        "-----------PARTE IV (2/2)--------------\n",
        "\n",
        "    Breve introdução\n",
        "    Separar em tóp.\n",
        "    Git hub (atualizar o git com o ep3)\n",
        "    Cabeçalho dos int\n",
        "    Comentar cód.\n",
        "    Organização do código e notebook \n",
        "    Read-me (pode ser o read-me do git atualizado)\n",
        "\n",
        "NOTA (10/10)"
      ],
      "id": "NJhezyASnB0F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mTzQJGJnHP_"
      },
      "source": [
        "# MAC0417/5768 - Visão e Processamento de Imagens (2021)\n",
        "\n",
        "Exercício Programa 3.2 - Classificação de imagens\n",
        "\n",
        "Gabriela Melo e Richard Block\n",
        "\n",
        "Projeto GitHub: https://github.com/gabi-melo/image_processing/tree/main/EP3\n",
        "\n",
        "Base de imagens: https://www.kaggle.com/gabrielamelo/image-processing\n"
      ],
      "id": "7mTzQJGJnHP_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5PdpfHenjKD"
      },
      "source": [
        "# Resumo"
      ],
      "id": "e5PdpfHenjKD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d831991"
      },
      "source": [
        "Nessa parte do EP realizamos a etapa de classificação, baseada nas imagens binárias com Feret Box obtidas na primeira parte. As imagens foram redimensionaras para que todas as classes apresentem o mesmo tamanho. Os dados foram separados em conjuntos de treino e de teste. Então foi executada uma etapa de preparação para o aprendizado, com a extração do vetor de características. Para isso, foi utilizada a análise de componentes principais (PCA). A PCA descobre os eixos/vetores de maior variância dos dados, fazendo uma análise a partir da matriz de covariância. O vetor que indica a maior variabilidade dos dados é o primeiro autovetor. O vetor perpendicular é o segundo autovetor, indicando o segundo vetor de maior variabilidade. A transformada PCA muda a coordenada dos pontos definida pelos autovetores, realizando a redução da dimensionalidade.\n",
        "\n",
        "O vetor de características resultante foi então submetido à classificação, utilizando um algoritmo de máquina de suporte vetorial (SVM). Um classificador define um modelo algébrico para qual é a superfície de decisão. O modelo mais simples é uma linha reta que divide o conjunto de dados para fazer a separação dos dados entre as diferentes classes. As máquinas de suporte vetorial procuram criar uma reta que define uma função critério, a qual é otimizada. O procedimento de otimização faz calcula qual é a linha reta que maximiza as distâncias dos pontos mais próximos da reta. O processo de treinamento de SVM descobre qual é essa linha reta que apresenta a maior distância possível de todas as classes. Esse treino foi realizado exclusivamente nos dados do conjunto de treino.\n",
        "Foram calculadas métricas de avaliação da qualidade do modelo nos dados do conjunto de teste. Foi realizada a predição dos rótulos das classes do conjunto de teste, e foram computadas variáveis da performance do classificador."
      ],
      "id": "0d831991"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptD4XbFejJMW"
      },
      "source": [
        "# Download do Kaggle dataset"
      ],
      "id": "ptD4XbFejJMW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyUtaynvT9M",
        "outputId": "05559fe2-5b70-4470-d39a-b718e3fd4dac"
      },
      "source": [
        "from glob import glob \n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "9cyUtaynvT9M",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icol7d7hv1-P"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "id": "Icol7d7hv1-P",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2Cq8blv7dD",
        "outputId": "5d9a494e-9984-4b89-a9d8-42a644a66637"
      },
      "source": [
        "# changing the working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "id": "PN2Cq8blv7dD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV1VeC5ZwLTY",
        "outputId": "b69f3af2-bbe2-42ee-838d-5ef60e7b42bb"
      },
      "source": [
        "!kaggle datasets download -d gabrielamelo/image-processing"
      ],
      "id": "hV1VeC5ZwLTY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image-processing.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaW0DCAtwWmp",
        "outputId": "fc3e7fdc-a0e4-451f-c729-39ba7d6c347d"
      },
      "source": [
        "# check content\n",
        "!ls /content"
      ],
      "id": "XaW0DCAtwWmp",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpC6q0Vfwe_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72676da-5b49-44dd-9407-e3b83c165a26"
      },
      "source": [
        "# unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "id": "KpC6q0Vfwe_Z",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  image-processing.zip\n",
            "replace augmentedDataset/augmentedDataset/caneta_1_dia_dentro_madeira_1_conv.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6f7270"
      },
      "source": [
        "# Classificação usando SVM"
      ],
      "id": "7d6f7270"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk2toRziweUs"
      },
      "source": [
        "## As imagens já foram pré-processadas, todas padronizadas no tamanho (64, 64)."
      ],
      "id": "Pk2toRziweUs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idLeFLurwvMG"
      },
      "source": [
        "### Podemos visualizar algumas das imagens."
      ],
      "id": "idLeFLurwvMG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_us6Bj7xDNZ"
      },
      "source": [
        "from time import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC"
      ],
      "id": "S_us6Bj7xDNZ",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btj3wZF91Z-6"
      },
      "source": [
        "# objects = fetch_lfw_people(data_home = 'path', download_if_missing=False) #carregar imagens"
      ],
      "id": "btj3wZF91Z-6",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIPQSda2wc8H"
      },
      "source": [
        "# fig = plt.figure(figsize=(8, 6))\n",
        "\n",
        "# for i in range(15):\n",
        "#     ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "#     ax.imshow(objects[i], cmap=plt.cm.bone)"
      ],
      "id": "tIPQSda2wc8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTEkfgLzxj2F"
      },
      "source": [
        "### Divisão da amostra em dados de treinamento e dados de teste"
      ],
      "id": "KTEkfgLzxj2F"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bse4_1SUFrVl",
        "outputId": "65a423fa-08a4-40ee-e4d8-e7661b15140f"
      },
      "source": [
        "paths = glob('/*.jpg') # path para os objects\n",
        "\n",
        "X = []\n",
        "\n",
        "for path in paths:\n",
        "\n",
        "  an_image = Image.open(path)\n",
        "  image_sequence = an_image.getdata()\n",
        "  image_array = np.array(image_sequence)\n",
        "  X.append(image_array)\n",
        "\n",
        "X = np.array(X)\n",
        "print(X)\n",
        "\n",
        "y = []\n",
        "\n",
        "for path in paths:\n",
        "    \n",
        "  img_class = path.split('/')[-1].split('_')[0]\n",
        "  y.append(img_class)\n",
        "\n",
        "y = np.array(y)\n",
        "print(y)"
      ],
      "id": "bse4_1SUFrVl",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  2   3   4 ... 164 164 163]\n",
            " [166 166 166 ... 126 108  97]\n",
            " [ 79  79  79 ... 124 124 124]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [ 11  25  30 ...  57  43  59]\n",
            " [ 54  54  54 ...  56  56  56]]\n",
            "['chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave'\n",
            " 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave'\n",
            " 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'chave'\n",
            " 'chave' 'chave' 'chave' 'chave' 'chave' 'chave' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta' 'caneta'\n",
            " 'caneta' 'caneta' 'caneta' 'caneta' 'caneta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sRtF-ATxrVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d848ee-c0ee-429c-f737-640030d97fd6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "id": "4sRtF-ATxrVF",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 480000) (50, 480000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPeEZ7A8x4_G"
      },
      "source": [
        "### PCA"
      ],
      "id": "QPeEZ7A8x4_G"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAYS_i-yMMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664a3d67-9627-4237-ee57-1e54966ad369"
      },
      "source": [
        "pca = PCA(n_components=150, whiten=True)\n",
        "pca.fit(X_train)"
      ],
      "id": "flAYS_i-yMMU",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqmmJq29yhrV"
      },
      "source": [
        "Um exemplo de objeto \"médio\""
      ],
      "id": "bqmmJq29yhrV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ok7rm8ByZn4"
      },
      "source": [
        "plt.imshow(pca.mean_.reshape(faces.images[0].shape),\n",
        "           cmap=plt.cm.bone)"
      ],
      "id": "-ok7rm8ByZn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akH-nEQRyomp"
      },
      "source": [
        "Os desvios em relação à média ao longo dos eixos ortogonais."
      ],
      "id": "akH-nEQRyomp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFHKCw81y4hR"
      },
      "source": [
        "print(pca.components_.shape)"
      ],
      "id": "VFHKCw81y4hR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS-kdr8Xy5Xi"
      },
      "source": [
        "### Visualização dos componentes principais, ordenados conforme importância."
      ],
      "id": "vS-kdr8Xy5Xi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJe_Vg5zAyl"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 6))\n",
        "for i in range(30):\n",
        "    ax = fig.add_subplot(3, 10, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(pca.components_[i].reshape(faces.images[0].shape),\n",
        "              cmap=plt.cm.bone)"
      ],
      "id": "fVJe_Vg5zAyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYFohPhhzMBA"
      },
      "source": [
        "Os dados de treinamento e de teste projetados nas bases do PCA."
      ],
      "id": "FYFohPhhzMBA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhgAiLdCzfR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7316d64-c309-4c1d-f8ca-e63b3a76997f"
      },
      "source": [
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "print(X_train_pca.shape)"
      ],
      "id": "AhgAiLdCzfR3",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1FuLaldzjAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ddf5b42-1ece-410e-8201-977eb7cd4bbf"
      },
      "source": [
        "print(X_test_pca.shape)"
      ],
      "id": "_1FuLaldzjAH",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a86nkr1BzkFf"
      },
      "source": [
        "## SVM"
      ],
      "id": "a86nkr1BzkFf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzm7mCzJztAV"
      },
      "source": [
        "clf = svm.SVC(C=5., gamma=0.001)\n",
        "clf.fit(X_train_pca, y_train)"
      ],
      "id": "Jzm7mCzJztAV",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEQvRjt3z1F-"
      },
      "source": [
        "### Visualização de alguns resultados: imagens com os rótulos aprendidos."
      ],
      "id": "jEQvRjt3z1F-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYAlhyp0z7VW"
      },
      "source": [
        "import numpy as np\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "for i in range(15):\n",
        "    ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(X_test[i].reshape(faces.images[0].shape),\n",
        "              cmap=plt.cm.bone)\n",
        "    y_pred = clf.predict(X_test_pca[i, np.newaxis])[0]\n",
        "    color = ('black' if y_pred == y_test[i] else 'red')\n",
        "    ax.set_title(y_pred, fontsize='small', color=color)"
      ],
      "id": "bYAlhyp0z7VW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuXKiMzZz8st"
      },
      "source": [
        "## Métricas de classificação"
      ],
      "id": "wuXKiMzZz8st"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX1bR5zp0XxR"
      },
      "source": [
        "### Precisão, Recall, F1-Score e Suporte"
      ],
      "id": "rX1bR5zp0XxR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAcIOX5p0MiV"
      },
      "source": [
        "y_pred = clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "id": "nAcIOX5p0MiV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmApuVcV0dH6"
      },
      "source": [
        "### Confusion-matrix\n",
        "Um classificador perfeito apresenta números diferentes de zero somente na diagonal principal, e zero no restante."
      ],
      "id": "xmApuVcV0dH6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvLXlDR0yBq"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "id": "zqvLXlDR0yBq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d4ad668"
      },
      "source": [
        "from time import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "# Display progress logs on stdout\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Download the data, if not already on disk and load it as numpy arrays\n",
        "# base de ROIs\n",
        "\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# introspect the images arrays to find the shapes (for plotting)\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "\n",
        "# for machine learning we use the 2 data directly (as relative pixel\n",
        "# positions info is ignored by this model)\n",
        "X = lfw_people.data\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# the label to predict is the id of the person\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "n_classes = target_names.shape[0]\n",
        "\n",
        "print(\"Total dataset size:\")\n",
        "print(\"n_samples: %d\" % n_samples)\n",
        "print(\"n_features: %d\" % n_features)\n",
        "print(\"n_classes: %d\" % n_classes)\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Split into a training set and a test set using a stratified k fold\n",
        "\n",
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# X = conjunto de dados/imagens\n",
        "# y = conjunto de rótulos\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
        "# dataset): unsupervised feature extraction / dimensionality reduction\n",
        "\n",
        "n_components = 150\n",
        "\n",
        "# calcula os autovetores/extração dos vetores de características\n",
        "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
        "      % (n_components, X_train.shape[0]))\n",
        "t0 = time()\n",
        "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
        "          whiten=True).fit(X_train)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
        "\n",
        "# calcula as dimensões da transformada de PCA\n",
        "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
        "t0 = time()\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Train a SVM classification model\n",
        "\n",
        "print(\"Fitting the classifier to the training set\")\n",
        "t0 = time()\n",
        "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
        "clf = GridSearchCV(\n",
        "    SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_train_pca, y_train) # ajuste da função critério\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\"Best estimator found by grid search:\")\n",
        "print(clf.best_estimator_)\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Quantitative evaluation of the model quality on the test set\n",
        "\n",
        "# predição dos rótulos do test set\n",
        "\n",
        "print(\"Predicting people's names on the test set\")\n",
        "t0 = time()\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "# variáveis da performance do classificador\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Qualitative evaluation of the predictions using matplotlib\n",
        "\n",
        "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "        plt.title(titles[i], size=12)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "\n",
        "\n",
        "# plot the result of the prediction on a portion of the test set\n",
        "\n",
        "def title(y_pred, y_test, target_names, i):\n",
        "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
        "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
        "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
        "\n",
        "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
        "                     for i in range(y_pred.shape[0])]\n",
        "\n",
        "plot_gallery(X_test, prediction_titles, h, w)\n",
        "\n",
        "# plot the gallery of the most significative eigenfaces\n",
        "\n",
        "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
        "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# precisão da acurácia da classificação\n",
        "# revocação captura, da amostra inteira, quantos objetos foram possíveis recuperar de cada classe\n",
        "# f1 \n",
        "# suporte\n",
        "\n",
        "# matriz de confusão coloca todas as classes nas linhas e colunas e mostra o que \n",
        "# foi classificado como o que"
      ],
      "id": "4d4ad668",
      "execution_count": null,
      "outputs": []
    }
  ]
}