{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of EP3_1_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Lb31rbgcn28T"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mTzQJGJnHP_"
      },
      "source": [
        "# MAC0417/5768 - Visão e Processamento de Imagens (2021)\n",
        "\n",
        "Exercício Programa 3.1 - Segmentação de imagens\n",
        "\n",
        "Gabriela Melo e Richard Block\n",
        "\n",
        "Projeto GitHub: https://github.com/gabi-melo/image_processing/tree/main/EP3\n",
        "\n",
        "Base de imagens: https://www.kaggle.com/gabrielamelo/image-processing\n"
      ],
      "id": "7mTzQJGJnHP_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5PdpfHenjKD"
      },
      "source": [
        "# Resumo\n",
        "\n",
        "Na primeira parte do EP realizamos a segmentação das imagens em níveis de cinza do dataset gerado no EP2. Duas formas de segmentação foram aplicadas: manual e automática. \n",
        "\n",
        "Para a segmentação manual, utilizamos cerca de 15% das imagens em níveis de cinza de cada classe de objetos. Foi empregado o programa Label Studio para a segmentação semântica com máscaras. A segmentação manual gerou imagens binárias, em que o valor de 0 corresponde ao fundo e o valor de 1 corresponde ao objeto, compondo o \"ground truth\" do dataset. Essas imagens binárias foram processadas utilizando um Feret Box para delimitar a área de interesse, fazendo com que a região a ser analisada na etapa de classificação (EP3.2) esteja restrita ao objeto, auxiliando a localização do objeto pelo algoritmo classificador.\n",
        "\n",
        "Para a segmentação automática usamos um método chamado U square Net, baseado numa arquitetura de rede profunda (disponível em https://arxiv.org/pdf/2005.09007.pdf). Métricas para a avaliação do modelo de segmentação foram computadas.\n",
        "\n"
      ],
      "id": "e5PdpfHenjKD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dza7XvA-w20E"
      },
      "source": [
        "# Download do Kaggle dataset"
      ],
      "id": "dza7XvA-w20E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyUtaynvT9M",
        "outputId": "c8d3a7dd-ca65-4fff-eb3b-f7805664c083"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "id": "9cyUtaynvT9M",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2Cq8blv7dD",
        "outputId": "9d686729-d1ca-43fd-c438-31c4e6a417b3"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!kaggle datasets download -d gabrielamelo/image-processing"
      ],
      "id": "PN2Cq8blv7dD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpC6q0Vfwe_Z"
      },
      "source": [
        "# unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "id": "KpC6q0Vfwe_Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOKEWw_iXQ5Z",
        "outputId": "3af68e2f-0bc0-4ad4-9da6-cb82b567cbf5"
      },
      "source": [
        "ls '/content/gdrive/My Drive/Kaggle/'"
      ],
      "id": "VOKEWw_iXQ5Z",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mground_truth\u001b[0m/  kaggle.json  \u001b[01;34mobjects\u001b[0m/  \u001b[01;34mpath\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZr-GNnio_ct"
      },
      "source": [
        "# Segmentação manual"
      ],
      "id": "rZr-GNnio_ct"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW8EeS77wRCQ"
      },
      "source": [
        "A segmentação manual foi realizada no programa Label Studio. As imagens binárias resultantes compõem o ground truth e estão salvas no dataset do Kaggle."
      ],
      "id": "mW8EeS77wRCQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgShM9KxkguN"
      },
      "source": [
        "from glob import glob \n",
        "\n",
        "# acessar o conteúdo do diretório das imagens ground truth\n",
        "for path in glob('/content/gdrive/My Drive/Kaggle/ground_truth/ground_truth/*.png'):\n",
        "    print(path)"
      ],
      "id": "vgShM9KxkguN",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "l3kfA-eYwUj5",
        "outputId": "11445d6f-643f-46a9-9d60-c0c365ef2d72"
      },
      "source": [
        "# exemplo de imagem ground truth\n",
        "\n",
        "ex_segm_manual = '/content/gdrive/My Drive/Kaggle/ground_truth/tesoura_38.png'\n",
        "ex_img = cv2.imread(ex_segm_manual, 0)\n",
        "plt.imshow(ex_img, cmap=plt.get_cmap('gray'))"
      ],
      "id": "l3kfA-eYwUj5",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f987ffebc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYuMsfDo7Ha"
      },
      "source": [
        "# Segmentação automática"
      ],
      "id": "vdYuMsfDo7Ha"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvAVgKs-nJDo"
      },
      "source": [
        "Separamos a tarefa de segmentação automática em duas partes:\n",
        "1. Criação das máscaras dos objetos, a segmentação de fato.\n",
        "2. O Feret Box / Blob da região dos objetos, e a padronização destes para a tarefa de classificação."
      ],
      "id": "rvAVgKs-nJDo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb31rbgcn28T"
      },
      "source": [
        "## 1.\n",
        "\n",
        "Fizemos uso de uma rede neural treinada, e usamos nossas imagens como testes da rede."
      ],
      "id": "Lb31rbgcn28T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GV4yFUQnGTy"
      },
      "source": [
        "# download do modelo pré-treinado\n",
        "!wget -O u2netp.pth https://drive.google.com/u/0/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy&export=download \n",
        "!wget -O u2netp.onnx https://drive.google.com/uc?id=1OPfir1PXZAABPEZpIppauGKDu8LYXoIm&authuser=0&export=download"
      ],
      "id": "0GV4yFUQnGTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNg4wBRdoNhA"
      },
      "source": [
        "#u2netp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "#import torch.nn.functional as F"
      ],
      "id": "GNg4wBRdoNhA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHCh4hiQpBIW"
      },
      "source": [
        "### Configurações da rede"
      ],
      "id": "pHCh4hiQpBIW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0RguzVJoRT6"
      },
      "source": [
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
        "        super(REBNCONV,self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return xout\n",
        "\n",
        "### RSU-7 ###\n",
        "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "#        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "# edit for onnx compatibility\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
        "        hx6up = self.upscore2(hx6d)\n",
        "        # print(hx6up.shape,hx5.shape)\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-6 ###\n",
        "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-5 ###\n",
        "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4 ###\n",
        "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4F ###\n",
        "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "##### U^2-Net ####\n",
        "class U2NET(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NET,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,32,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,32,128)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128,64,256)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256,128,512)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512,256,512)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512,256,512)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(1024,256,512)\n",
        "        self.stage4d = RSU4(1024,128,256)\n",
        "        self.stage3d = RSU5(512,64,128)\n",
        "        self.stage2d = RSU6(256,32,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(128,1,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(256,1,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(512,1,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(512,1,3,padding=1)\n",
        "\n",
        "        self.upscore6 = nn.Upsample(scale_factor=32,mode='bilinear',align_corners=True)\n",
        "        self.upscore5 = nn.Upsample(scale_factor=16,mode='bilinear',align_corners=True)\n",
        "        self.upscore4 = nn.Upsample(scale_factor=8,mode='bilinear',align_corners=True)\n",
        "        self.upscore3 = nn.Upsample(scale_factor=4,mode='bilinear',align_corners=True)\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear',align_corners=True)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = self.upscore2(hx6)\n",
        "\n",
        "        #-------------------- decoder --------------------\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = self.upscore2(d2)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = self.upscore3(d3)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = self.upscore4(d4)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = self.upscore5(d5)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = self.upscore6(d6)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "\n",
        "        F.sigmokd\n",
        "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)\n",
        "\n",
        "### U^2-Net small ###\n",
        "class U2NETP(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NETP,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,16,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,16,64)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(64,16,64)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(64,16,64)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(64,16,64)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(64,16,64)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(128,16,64)\n",
        "        self.stage4d = RSU4(128,16,64)\n",
        "        self.stage3d = RSU5(128,16,64)\n",
        "        self.stage2d = RSU6(128,16,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(64,1,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(64,1,3,padding=1)\n",
        "\n",
        "        self.upscore6 = nn.Upsample(scale_factor=32,mode='bilinear',align_corners=True)\n",
        "        self.upscore5 = nn.Upsample(scale_factor=16,mode='bilinear',align_corners=True)\n",
        "        self.upscore4 = nn.Upsample(scale_factor=8,mode='bilinear',align_corners=True)\n",
        "        self.upscore3 = nn.Upsample(scale_factor=4,mode='bilinear',align_corners=True)\n",
        "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear',align_corners=True)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = self.upscore2(hx6)\n",
        "\n",
        "        #decoder\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = self.upscore2(hx5d)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = self.upscore2(hx4d)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = self.upscore2(hx3d)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = self.upscore2(hx2d)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = self.upscore2(d2)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = self.upscore3(d3)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = self.upscore4(d4)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = self.upscore5(d5)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = self.upscore6(d6)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "        # d00 = d0 + self.refconv(d0)\n",
        "\n",
        "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)"
      ],
      "id": "w0RguzVJoRT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1coQ-SYpLuW"
      },
      "source": [
        "net = U2NETP(3,1)"
      ],
      "id": "J1coQ-SYpLuW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIP48-PzpWFK"
      },
      "source": [
        "### Data loader e transformaçções das imagens para serem usadas na rede neural"
      ],
      "id": "OIP48-PzpWFK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R_8xgxXpOR7"
      },
      "source": [
        "# data loader\n",
        "from __future__ import print_function, division\n",
        "import glob\n",
        "import torch\n",
        "from skimage import io, transform, color\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "#==========================dataset load==========================\n",
        "class RescaleT(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\t# img = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\t# lbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\timg = transform.resize(image,(self.output_size,self.output_size),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(self.output_size,self.output_size),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\timg = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class RandomCrop(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size, (int, tuple))\n",
        "\t\tif isinstance(output_size, int):\n",
        "\t\t\tself.output_size = (output_size, output_size)\n",
        "\t\telse:\n",
        "\t\t\tassert len(output_size) == 2\n",
        "\t\t\tself.output_size = output_size\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\ttop = np.random.randint(0, h - new_h)\n",
        "\t\tleft = np.random.randint(0, w - new_w)\n",
        "\n",
        "\t\timage = image[top: top + new_h, left: left + new_w]\n",
        "\t\tlabel = label[top: top + new_h, left: left + new_w]\n",
        "\n",
        "\t\treturn {'imidx':imidx,'image':image, 'label':label}\n",
        "\n",
        "class ToTensor(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\timage = image/np.max(image)\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\tif image.shape[2]==1:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\telse:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class ToTensorLab(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\tdef __init__(self,flag=0):\n",
        "\t\tself.flag = flag\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label =sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\t# change the color space\n",
        "\t\tif self.flag == 2: # with rgb and Lab colors\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],6))\n",
        "\t\t\ttmpImgt = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImgt[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImgt = image\n",
        "\t\t\ttmpImgtl = color.rgb2lab(tmpImgt)\n",
        "\n",
        "\t\t\t# nomalize image to range [0,1]\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImgt[:,:,0]-np.min(tmpImgt[:,:,0]))/(np.max(tmpImgt[:,:,0])-np.min(tmpImgt[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImgt[:,:,1]-np.min(tmpImgt[:,:,1]))/(np.max(tmpImgt[:,:,1])-np.min(tmpImgt[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImgt[:,:,2]-np.min(tmpImgt[:,:,2]))/(np.max(tmpImgt[:,:,2])-np.min(tmpImgt[:,:,2]))\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImgtl[:,:,0]-np.min(tmpImgtl[:,:,0]))/(np.max(tmpImgtl[:,:,0])-np.min(tmpImgtl[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImgtl[:,:,1]-np.min(tmpImgtl[:,:,1]))/(np.max(tmpImgtl[:,:,1])-np.min(tmpImgtl[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImgtl[:,:,2]-np.min(tmpImgtl[:,:,2]))/(np.max(tmpImgtl[:,:,2])-np.min(tmpImgtl[:,:,2]))\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImg[:,:,3]-np.mean(tmpImg[:,:,3]))/np.std(tmpImg[:,:,3])\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImg[:,:,4]-np.mean(tmpImg[:,:,4]))/np.std(tmpImg[:,:,4])\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImg[:,:,5]-np.mean(tmpImg[:,:,5]))/np.std(tmpImg[:,:,5])\n",
        "\n",
        "\t\telif self.flag == 1: #with Lab color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg = image\n",
        "\n",
        "\t\t\ttmpImg = color.rgb2lab(tmpImg)\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.min(tmpImg[:,:,0]))/(np.max(tmpImg[:,:,0])-np.min(tmpImg[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.min(tmpImg[:,:,1]))/(np.max(tmpImg[:,:,1])-np.min(tmpImg[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.min(tmpImg[:,:,2]))/(np.max(tmpImg[:,:,2])-np.min(tmpImg[:,:,2]))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\n",
        "\t\telse: # with rgb color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\timage = image/np.max(image)\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class SalObjDataset(Dataset):\n",
        "\tdef __init__(self,img_name_list,lbl_name_list,transform=None):\n",
        "\t\t# self.root_dir = root_dir\n",
        "\t\t# self.image_name_list = glob.glob(image_dir+'*.png')\n",
        "\t\t# self.label_name_list = glob.glob(label_dir+'*.png')\n",
        "\t\tself.image_name_list = img_name_list\n",
        "\t\tself.label_name_list = lbl_name_list\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.image_name_list)\n",
        "\n",
        "\tdef __getitem__(self,idx):\n",
        "\n",
        "\t\t# image = Image.open(self.image_name_list[idx])#io.imread(self.image_name_list[idx])\n",
        "\t\t# label = Image.open(self.label_name_list[idx])#io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\timage = io.imread(self.image_name_list[idx])\n",
        "\t\timname = self.image_name_list[idx]\n",
        "\t\timidx = np.array([idx])\n",
        "\n",
        "\t\tif(0==len(self.label_name_list)):\n",
        "\t\t\tlabel_3 = np.zeros(image.shape)\n",
        "\t\telse:\n",
        "\t\t\tlabel_3 = io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\tlabel = np.zeros(label_3.shape[0:2])\n",
        "\t\tif(3==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3[:,:,0]\n",
        "\t\telif(2==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3\n",
        "\n",
        "\t\tif(3==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\t\telif(2==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\timage = image[:,:,np.newaxis]\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\n",
        "\t\tsample = {'imidx':imidx, 'image':image, 'label':label}\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\tsample = self.transform(sample)\n",
        "\n",
        "\t\treturn sample"
      ],
      "id": "8R_8xgxXpOR7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTibvwMopnAj"
      },
      "source": [
        "### Obtenção dos nossos dados para serem usados como teste da rede"
      ],
      "id": "YTibvwMopnAj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yD6378epiRx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "2yD6378epiRx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvMwUw4p4Z8"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/kaggle'"
      ],
      "id": "uJvMwUw4p4Z8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGsqtfBp7Lo"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/kaggle"
      ],
      "id": "DNGsqtfBp7Lo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ojU-R3_p9s3"
      },
      "source": [
        "!kaggle datasets download -d richardbarana/ep3-usp"
      ],
      "id": "8ojU-R3_p9s3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnuI-BMtqBJk"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "id": "WnuI-BMtqBJk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gf6EIO5qLxG"
      },
      "source": [
        "### Inicialização do modelo"
      ],
      "id": "4Gf6EIO5qLxG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1G3DyzzqEL9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms#, utils\n",
        "\n",
        "model_dir = './u2netp.pth'\n",
        "net.load_state_dict(torch.load(model_dir))\n",
        "if torch.cuda.is_available():\n",
        "  print(\"cuda is available\")\n",
        "  net.cuda()\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "id": "F1G3DyzzqEL9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVikVmgaqS7Q"
      },
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "\n",
        "# Create the right input shape (e.g. for an image)\n",
        "dummy_input = torch.randn(1, 3, 320, 320).cuda()\n",
        "\n",
        "torch.onnx.export(net, dummy_input, \"onnx_u2netp.onnx\", opset_version=11)\n",
        "# UserWarning: You are trying to export the model with onnx:Upsample for ONNX opset version 9.\n",
        "# This operator might cause results to not match the expected results by PyTorch.\n",
        "# ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11.\n",
        "# Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior \n",
        "# (like coordinate_transformation_mode and nearest_mode).\n",
        "# We recommend using opset 11 and above for models using this operator. \n",
        "#   \"\" + str(_export_onnx_opset_version) + \". \"\n",
        "# /usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_helper.py:182: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
        "#   warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")"
      ],
      "id": "kVikVmgaqS7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLd6tlrgqYeq"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/kaggle/augmentedDataset/"
      ],
      "id": "PLd6tlrgqYeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXGQ03DNqfHR"
      },
      "source": [
        "### Teste do modelo com as nossas imagens, e máscaras das imagens salvas"
      ],
      "id": "wXGQ03DNqfHR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0J-6mW5qb7v"
      },
      "source": [
        "img_name_list = glob.glob('./*.jpg')\n",
        "img_name_list"
      ],
      "id": "x0J-6mW5qb7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnpARr5yqmyF"
      },
      "source": [
        "net.eval()"
      ],
      "id": "lnpARr5yqmyF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTvYfxQcqqrX"
      },
      "source": [
        "test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
        "                                    lbl_name_list = [],\n",
        "                                    transform=transforms.Compose([RescaleT(320),\n",
        "                                                                  ToTensorLab(flag=0)])\n",
        "                                    )\n",
        "test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=1)"
      ],
      "id": "uTvYfxQcqqrX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6183OPHq2Ev"
      },
      "source": [
        "path_masks = r'/content/drive/My Drive/kaggle/masks/'\n",
        "\n",
        "def normPRED(d):\n",
        "    ma = torch.max(d)\n",
        "    mi = torch.min(d)\n",
        "\n",
        "    dn = (d-mi)/(ma-mi)\n",
        "\n",
        "    return dn\n",
        "\n",
        "\n",
        "def genImage(image_name,pred):\n",
        "\n",
        "    predict = pred\n",
        "    predict = predict.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
        "    img_name = image_name.split(\"/\")[-1]\n",
        "    image = io.imread(image_name)\n",
        "    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
        "\n",
        "    pb_np = np.array(imo)\n",
        "\n",
        "    aaa = img_name.split(\".\")\n",
        "    bbb = aaa[0:-1]\n",
        "    imidx = bbb[0]\n",
        "    for i in range(1,len(bbb)):\n",
        "        imidx = imidx + \".\" + bbb[i]\n",
        "\n",
        "    file_path = os.path.join(path_masks, img_name)\n",
        "    imo.save(file_path)\n",
        "\n",
        "    return imo\n",
        "\n",
        "# test_salobj_dataloader 에서 i_test랑 data_test를 어떻게 뽑아내지?\n",
        "for i_test, data_test in enumerate(test_salobj_dataloader):\n",
        "    print(\"inferencing:\",img_name_list[i_test].split(\"/\")[-1])\n",
        "    inputs_test = data_test['image']\n",
        "    inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "    inputs_test = Variable(inputs_test.cuda())\n",
        "    # inputs_test = Variable(inputs_test)\n",
        "    d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
        "\n",
        "    pred = d1[:,0,:,:]\n",
        "    pred = normPRED(pred)\n",
        "\n",
        "    genImage(img_name_list[i_test],pred)"
      ],
      "id": "-6183OPHq2Ev",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eTUW6IThK3K"
      },
      "source": [
        "## 2."
      ],
      "id": "3eTUW6IThK3K"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnezyGVheem"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from skimage import io"
      ],
      "id": "JsnezyGVheem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O6SmHoEhhRJ"
      },
      "source": [
        "%cd /content/drive/My Drive/kaggle"
      ],
      "id": "7O6SmHoEhhRJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5o6LnjhkrO"
      },
      "source": [
        "masks = []\n",
        "for root, dirs, files in os.walk('./masks'):\n",
        "    masks += glob.glob(os.path.join(root, '*.jpg'))"
      ],
      "id": "VL5o6LnjhkrO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMPohW_6hm0M"
      },
      "source": [
        "aug = []\n",
        "for root, dirs, files in os.walk('./augmentedDataset'):\n",
        "    aug += glob.glob(os.path.join(root, '*.jpg'))"
      ],
      "id": "SMPohW_6hm0M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMdWuecAhpLH"
      },
      "source": [
        "for idx, val in enumerate(masks):\n",
        "  im_mask = cv2.imread(val, 0)\n",
        "  im_name = val.split(\"/\")[-1]\n",
        "\n",
        "# Achar os contornos das máscaras\n",
        "  ret, thresh = cv2.threshold(im_mask, 127, 255, 0)\n",
        "  contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnt = contours[0]\n",
        "\n",
        "# Pegar as coordenadas dos retângulos e desenha-lo\n",
        "  x, y, w, h = cv2.boundingRect(cnt)\n",
        "  cv2.rectangle(im_mask, (x,y), (x+w, y+h), (0,255,0), 2)\n",
        "\n",
        "# Recortar os objetos das imagens e rescalar as imagens para classificação\n",
        "  im_aug = cv2.imread(aug[idx], 0)\n",
        "  cropped = im_aug[y-2:y+h+2, x-2:x+w+2]\n",
        "  res = cv2.resize(cropped, dsize=(64,64))\n",
        "  im_res = Image.fromarray(res)\n",
        "\n",
        "# Salvar as imagens\n",
        "  file_path = os.path.join('./objects', im_name)\n",
        "  im_res.save(file_path)"
      ],
      "id": "wMdWuecAhpLH",
      "execution_count": null,
      "outputs": []
    }
  ]
}